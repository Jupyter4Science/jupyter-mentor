# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_llm.ipynb.

# %% auto 0
__all__ = ['LLM', 'FileModel']

# %% ../nbs/02_llm.ipynb 1
from traitlets import HasTraits, Unicode, List
from langchain_openai import ChatOpenAI
import os
from langchain.docstore.document import Document
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# %% ../nbs/02_llm.ipynb 2
class LLM(HasTraits):

    def __init__(self, filepath='OPENAI_API_KEY'):
        super().__init__()

        with open(filepath, 'r') as file:
            openai_api_key = file.read().strip()
        os.environ['OPENAI_API_KEY'] = openai_api_key
        self.llm = ChatOpenAI(model_name="gpt-3.5-turbo")

# %% ../nbs/02_llm.ipynb 4
class FileModel(LLM):
    # Define a Unicode string trait
    select = Unicode()
    files = List()

    def __init__(self, course_file_dir = 'course_files/'):
        super().__init__()
        self.course_file_dir = course_file_dir
        self.embeddings = OpenAIEmbeddings()
        self.db = None

    def save_content_from_upload(values):
        for value in values:
            with open(filepath + value['name'], "wb") as fp:
                fp.write(value['content'])

    def load_text_to_db(self, text):
        doc = Document(page_content=text)
        db = FAISS.from_documents(doc, self.embeddings)
        if self.db:
            self.db.merge_from(db)
        else: 
            self.db = db

    def load_pdf_to_db(self, filepath):
        loader = PyPDFLoader(filepath) 
        pages = loader.load_and_split()
        db = FAISS.from_documents(pages, self.embeddings)
        if self.db:
            self.db.merge_from(db)
        else: 
            self.db = db
        self.files.append(filepath)

    def load_markdown_to_db(filepath):
        loader = UnstructuredMarkdownLoader(filepath, mode="elements") #mode=elements breaks up the text into chunks
        doc = loader.load()
        db = FAISS.from_documents(doc, embeddings)
        if self.db:
            self.db.merge_from(db)
        else: 
            self.db = db
        self.files.append(filepath)

    def save_content_from_upload(values):
        for value in values:
            with open(value['name'], "wb") as fp:
                fp.write(value['content'])
